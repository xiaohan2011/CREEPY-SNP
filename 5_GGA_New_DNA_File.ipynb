{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:52:17.880942800Z",
     "start_time": "2023-10-31T22:52:17.063277Z"
    }
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.Restriction import *\n",
    "import pandas as pd\n",
    "import os\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Input filename\n",
    "template = \"pXW466.fa\"\n",
    "vector = \"pXW467.fa\"\n",
    "primer = 'primers.txt'\n",
    "primer2 = 'pXW470_creepy_primer_2023-10-30_18-21-24.txt'\n",
    "\n",
    "#Output filename (partial)\n",
    "gga_product_file = \"GGA_product_\" \n",
    "\n",
    "desktop = os.path.expanduser(\"~/Desktop\")\n",
    "template = desktop + \"/\" + template\n",
    "vector = desktop + \"/\" + vector\n",
    "primer_path = desktop + '/' + primer\n",
    "primer_path_2 = desktop + '/' + primer2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:52:17.912190Z",
     "start_time": "2023-10-31T22:52:17.880942800Z"
    }
   },
   "id": "9e13b2d6f1345a98"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load the fasta sequence from the file\n",
    "def load_fasta_sequence(file_path):\n",
    "    with open(file_path, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            return record.seq.upper()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:52:17.912190Z",
     "start_time": "2023-10-31T22:52:17.896564200Z"
    }
   },
   "id": "81b75d6baf56b90a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Function to load primer pairs from a file\n",
    "def load_primer_pairs(file_path):\n",
    "    primer_pairs = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        for i in range(1, len(lines), 2):\n",
    "            forward_primer = lines[i].split('\\t')[1]\n",
    "            reverse_primer = lines[i + 1].split('\\t')[1]\n",
    "            primer_pairs.append((Seq(forward_primer.upper()), Seq(reverse_primer.upper())))\n",
    "    return pd.DataFrame(primer_pairs, columns=['Fwd', 'Rev'])        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:52:18.276570100Z",
     "start_time": "2023-10-31T22:52:18.260943300Z"
    }
   },
   "id": "4cb1f02d08e73cb8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Load the data from the text file\n",
    "def load_primer_pairs_2(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "    \n",
    "    # Initialize lists to store the primer names and sequences\n",
    "    primer_names = []\n",
    "    primer_sequences = []\n",
    "    \n",
    "    # Flag to start recording primer data\n",
    "    record_primers = False\n",
    "    \n",
    "    # Iterate through the lines in the file\n",
    "    for line in lines:\n",
    "        # Check if the lowercase version of the line contains \"primer\" to start recording primer data\n",
    "        if \"primer\" in line.lower():\n",
    "            record_primers = True\n",
    "            continue\n",
    "        \n",
    "        # Stop recording when other information begins\n",
    "        if not line.strip():\n",
    "            record_primers = False\n",
    "        \n",
    "        # If we are recording primer data, split the line and extract the primer name and sequence\n",
    "        if record_primers:\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                primer_name = parts[0]\n",
    "                primer_sequence = Seq(parts[1].strip())\n",
    "                primer_names.append(primer_name)\n",
    "                primer_sequences.append(Seq(primer_sequence.upper()))\n",
    "    \n",
    "    # Create a Pandas DataFrame from the collected data\n",
    "    data = {'Primer': primer_names, 'Sequence': primer_sequences}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return  df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:52:18.754181900Z",
     "start_time": "2023-10-31T22:52:18.697289100Z"
    }
   },
   "id": "95a2ad26652dd2eb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Function for PCR amplification with sticky ends\n",
    "def pcr_amplification_with_sticky_ends(template, forward_primer, reverse_primer):\n",
    "    # Define the sequences for sticky ends\n",
    "    fwd_anneal = forward_primer[-15:]\n",
    "    rev_anneal_rc = reverse_primer[-15:].reverse_complement()\n",
    "    \n",
    "    # Find the positions where the sticky ends anneal to the template\n",
    "    fwd_anneal_pos = template.find(fwd_anneal)\n",
    "    rev_anneal_pos = template.find(rev_anneal_rc)\n",
    "    \n",
    "    # Check if both sticky ends are present in the template\n",
    "    if fwd_anneal_pos != -1 and rev_anneal_pos != -1:\n",
    "        # Extract the template regions between the sticky ends\n",
    "        template_region = template[fwd_anneal_pos + len(fwd_anneal):rev_anneal_pos]\n",
    "        \n",
    "        # Amplify the template region with the primers\n",
    "        pcr_product = forward_primer + template_region + reverse_primer.reverse_complement()\n",
    "        print(f\"Amplified template with {str(forward_primer)} and {str(reverse_primer)}.\")\n",
    "        \n",
    "        return pcr_product\n",
    "\n",
    "    else:\n",
    "        # One or both sticky ends are not present in the template\n",
    "        print(f\"WARNING: primers {str(forward_primer)} and {str(reverse_primer)} do NOT amplify the template.\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:52:19.878280300Z",
     "start_time": "2023-10-31T22:52:19.843004600Z"
    }
   },
   "id": "b383516f4e62999f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def batch_pcr(p_df, temp_seq):\n",
    "    pcr_prod_list = []\n",
    "    \n",
    "    for i in range(0, p_df.shape[0], 2):\n",
    "        try: product = pcr_amplification_with_sticky_ends(temp_seq, p_df['Sequence'][i], p_df['Sequence'][i+1])\n",
    "        except None: pass\n",
    "        pcr_prod_list.append(product)\n",
    "        \n",
    "    return pcr_prod_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:52:20.274625Z",
     "start_time": "2023-10-31T22:52:20.234272300Z"
    }
   },
   "id": "69b19b8b98518626"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def batch_digestion_esp3i(pcr_list):\n",
    "    pcr_dig_list = []\n",
    "    for i in range(len(pcr_list)):\n",
    "        pcr_dig_list.append(Esp3I.catalyze(pcr_list[i]))\n",
    "    return pcr_dig_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:52:20.616372300Z",
     "start_time": "2023-10-31T22:52:20.578596300Z"
    }
   },
   "id": "2d15e4a10cea5f9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Use gga_liation_4 or gga_ligation_3 instead\n",
    "def gga_ligation(vect_dig, insert_list):\n",
    "    final_prod = vect_dig[0]\n",
    "    \n",
    "    if vect_dig[1][:4] == insert_list[0][1][:4]:\n",
    "        final_prod = final_prod + insert_list[0][1]\n",
    "        print(f'ligating fragment 1')\n",
    "\n",
    "    for i in range(len(insert_list)-1):\n",
    "        if insert_list[i][2][:4] == insert_list[i+1][1][:4]:\n",
    "            final_prod = final_prod + insert_list[i+1][1]\n",
    "            print(f'ligating fragment {i+2}')\n",
    "            \n",
    "    if insert_list[-1][2][:4] == vect_dig[2][:4]:\n",
    "        final_prod = final_prod + vect_dig[2]       \n",
    "        \n",
    "    return final_prod  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:52:21.001387100Z",
     "start_time": "2023-10-31T22:52:20.964607Z"
    }
   },
   "id": "26173c0e1ac5f462"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Use gga_liation_4 or gga_ligation_3 instead\n",
    "def gga_ligation_2(vect_dig, insert_list):\n",
    "    final_prod = vect_dig[0]\n",
    "    \n",
    "    sticky_end = {}\n",
    "    if vect_dig[1][:4] == insert_list[0][1][:4]:\n",
    "        final_prod = final_prod + insert_list[0][1]\n",
    "        print(f'ligating fragment 1')\n",
    "\n",
    "    for i in range(len(insert_list)-1):\n",
    "        if insert_list[i][2][:4] == insert_list[i+1][1][:4]:\n",
    "            final_prod = final_prod + insert_list[i+1][1]\n",
    "            print(f'ligating fragment {i+2}')\n",
    "            \n",
    "    if insert_list[-1][2][:4] == vect_dig[2][:4]:\n",
    "        final_prod = final_prod + vect_dig[2]       \n",
    "                \n",
    "    return final_prod   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:52:21.402038500Z",
     "start_time": "2023-10-31T22:52:21.353644500Z"
    }
   },
   "id": "f74a5d201d58d310"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "def make_sticky_ends_df(vect_frag, insert_list):\n",
    "    # Initialize lists to store the extracted sticky ends\n",
    "    sticky_ends1 = ['NA']\n",
    "    sticky_ends2 = [str(vect_frag[1][:4])]\n",
    "    \n",
    "    # Extract the first 4 bases from the last 2 Seq objects in each tuple\n",
    "    for tup in insert_list:\n",
    "        sticky_end1 = str(tup[1][:4])\n",
    "        sticky_end2 = str(tup[2][:4])\n",
    "        sticky_ends1.append(sticky_end1)\n",
    "        sticky_ends2.append(sticky_end2)\n",
    "    \n",
    "    sticky_ends1.append(str(vect_frag[2][:4]))\n",
    "    sticky_ends2.append('NA')\n",
    "    \n",
    "    # Create a Pandas DataFrame from the collected data\n",
    "    data = {'Sticky_End1': sticky_ends1, 'Sticky_End2': sticky_ends2}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c5e5551dd66f2e6"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def make_sticky_ends_df_2(frag_list):\n",
    "    sticky_ends1 = []\n",
    "    sticky_ends2 = []\n",
    "    frags1 = []\n",
    "    frags2 = []\n",
    "    frags3 = []\n",
    "    \n",
    "    if type(frag_list) == list:\n",
    "                \n",
    "        # Extract the first 4 bases from the last 2 Seq objects in each tuple\n",
    "        for tup in frag_list:\n",
    "            sticky_end1 = str(tup[1][:4])\n",
    "            sticky_end2 = str(tup[2][:4])\n",
    "            frag1 = str(tup[0])\n",
    "            frag2 = str(tup[1])\n",
    "            frag3 = str(tup[2])\n",
    "            sticky_ends1.append(sticky_end1)\n",
    "            sticky_ends2.append(sticky_end2)\n",
    "            frags1.append(frag1)\n",
    "            frags2.append(frag2)\n",
    "            frags3.append(frag3)\n",
    "            \n",
    "    elif type(frag_list) == tuple:\n",
    "        sticky_ends1.append(str(frag_list[1][:4]))\n",
    "        sticky_ends2.append(str(frag_list[2][:4]))\n",
    "        frags1.append(str(frag_list[0]))\n",
    "        frags2.append(str(frag_list[1]))\n",
    "        frags3.append(str(frag_list[2]))\n",
    "        \n",
    "    else:\n",
    "        print('Object type error')\n",
    "        \n",
    "    # Create a Pandas DataFrame from the collected data\n",
    "    data = {'Sticky_End1': sticky_ends1, 'Sticky_End2': sticky_ends2, 'Frag_0': frags1, 'Frag_1': frags2, 'Frag_2': frags3}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T00:25:35.529555Z",
     "start_time": "2023-11-01T00:25:35.496593700Z"
    }
   },
   "id": "1623570e5be1e109"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "def gga_ligation_3(vect_dig, insert_list):\n",
    "    \"\"\"\n",
    "    Perform golden gate ligation. Takes the vector digestion and the insert digestion list\n",
    "    :param vect_dig: a tuple, generated by Esp3I.catalyze(vector_seq)\n",
    "    :param insert_list: a list, each element is a tuple generated by Esp3I.catalyze(vector_seq)\n",
    "    !!! The adjacent insert fragments must have compatible sticky ends !!! \n",
    "    :return: the final ligated DNA sequence (Seq() object)\n",
    "    \"\"\"\n",
    "    #Initialize final_prod to be the left part of the digested vector first:\n",
    "    final_prod = vect_dig[0]\n",
    "    \n",
    "    sticky_ends_df = make_sticky_ends_df(vect_dig, insert_list)\n",
    "    \n",
    "    # Check if adjacent sticky ends are compatible:\n",
    "    for i in range(sticky_ends_df.shape[0]-1):\n",
    "        if sticky_ends_df['Sticky_End2'][i] != sticky_ends_df['Sticky_End1'][i+1]:\n",
    "            print(f'Sticky end #{i+1} is not compatible')\n",
    "            break\n",
    "    \n",
    "    # Check if all sticky ends are unique and none are not ligating with reverse complements:\n",
    "    sticky_ends_df['Sticky_End1_RevComp'] = sticky_ends_df['Sticky_End1'].apply(lambda x: str(Seq(x).reverse_complement()))\n",
    "    are_all_unique = pd.concat([sticky_ends_df['Sticky_End1'][1:], sticky_ends_df['Sticky_End1_RevComp'][1:]]).is_unique\n",
    "    if not are_all_unique:\n",
    "        print('WARNING: some sticky ends are not unique')\n",
    "        pass\n",
    "   \n",
    "    for i in range(len(insert_list)):\n",
    "        final_prod = final_prod + insert_list[i][1]\n",
    "        print(f'ligating fragment {i+1}')\n",
    "    \n",
    "    final_prod = final_prod + vect_dig[2]       \n",
    "               \n",
    "    return final_prod   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1a2a5bc3be663ed"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def gga_ligation_4(vect_dig, insert_list):\n",
    "    \"\"\"\n",
    "    Perform golden gate ligation. Takes the vector digestion and the insert digestion list\n",
    "    :param vect_dig: a tuple, generated by Esp3I.catalyze(vector_seq)\n",
    "    :param insert_list: a list, each element is a tuple generated by Esp3I.catalyze(vector_seq)\n",
    "    !!! Insert fragment order does not matter, the code will search for compatible sticky end!!! \n",
    "    :return: the final ligated DNA sequence (Seq() object)\n",
    "    \"\"\"\n",
    "    # Digest vector and inserts with Esp3I, return a df for each.\n",
    "    # Each df contains 5 columns: 'Sticky_End1', 'Sticky_End2', 'Frag_0', 'Frag_1', 'Frag_2'\n",
    "    vect_dig_df = make_sticky_ends_df_2(vect_dig)\n",
    "    insert_dig_df = make_sticky_ends_df_2(insert_list)\n",
    "\n",
    "    # Check if all sticky ends (including rc) are unique:\n",
    "    insert_dig_df['Sticky_End1_RevComp'] = insert_dig_df['Sticky_End1'].apply(lambda x: str(Seq(x).reverse_complement()))\n",
    "    insert_dig_df['Sticky_End2_RevComp'] = insert_dig_df['Sticky_End2'].apply(lambda x: str(Seq(x).reverse_complement()))\n",
    "\n",
    "    are_left_end_unique = pd.concat([insert_dig_df['Sticky_End1'], insert_dig_df['Sticky_End1_RevComp']]).is_unique\n",
    "    are_right_end_unique = pd.concat([insert_dig_df['Sticky_End2'], insert_dig_df['Sticky_End2_RevComp']]).is_unique\n",
    "\n",
    "    if not (are_left_end_unique and are_right_end_unique):\n",
    "        print('WARNING: some sticky ends are not unique')\n",
    "        pass\n",
    "    \n",
    "    # Initialize final product with the left part of the vector\n",
    "    final_prod = vect_dig_df['Frag_0'][0]\n",
    "    # Initialize left sticky end with vector sticky end #1\n",
    "    lse = vect_dig_df['Sticky_End1'][0]\n",
    "    # Initialize right sticky end with ''\n",
    "    rse = ''\n",
    "    count = 0\n",
    "    \n",
    "    while rse != vect_dig_df['Sticky_End2'][0]:\n",
    "        frag_index = insert_dig_df.index[insert_dig_df['Sticky_End1'] == lse].tolist()[0]\n",
    "        rse = insert_dig_df['Sticky_End2'][frag_index]\n",
    "        frag = insert_dig_df['Frag_1'][frag_index]\n",
    "        final_prod += frag\n",
    "        lse = rse\n",
    "        print(f'ligating fragment #{frag_index+1}')\n",
    "        count += 1\n",
    "    \n",
    "    if count != len(insert_list):\n",
    "        print('WARNING: Some fragments are not ligated in')\n",
    "        \n",
    "    final_prod += vect_dig_df['Frag_2'][0]    \n",
    " \n",
    "    return Seq(final_prod)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T00:56:41.608156700Z",
     "start_time": "2023-11-01T00:56:41.592152400Z"
    }
   },
   "id": "9b043c1e7488dbdb"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# Load plasmid sequences and  primer pairs:\n",
    "template_sequence = load_fasta_sequence(template)\n",
    "vector_sequence = load_fasta_sequence(vector)\n",
    "primer_df = load_primer_pairs_2(primer_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T00:38:02.067347500Z",
     "start_time": "2023-11-01T00:38:02.023430500Z"
    }
   },
   "id": "f7260c6f4cf792db"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amplified template with ACGTCTCCGACTTTAGAAAGTGAGTCATTTTGGGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCCCACAGCATGGTTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGTGGCCAAGCAGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCATGCTCAGCCTTTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGCATCTGCGCAGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTCTATCAGAATATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCTAGATAACTCTAGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCCCTAGAGGCTTCATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCTAGGGCTTCTCGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTAGTAATTTTTCTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCACTAGCCATAATGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTTTTACTACCGGTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCAAAAATTCATTTGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCGTTAGTGGTGGCTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCTAACAGCCACAGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCAGAAGGAAGCCATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCTTCTAGAAAGGCGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTTCCTCTGTGTATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGGAAAGAGGAAGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCGCAGCCATGTCTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCCTGCACATTTTCTGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCCAGTTGCAGGTTGCATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCACTGATCTGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCCTTCCCCTTCCGTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGAAGAAGGGGCCGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTCTCTGAGGCATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGAGAATTTCTCTAGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCGCTCTCCTCTGCTTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGAGCACGCGTGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCGTCAAAGGGATTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCTGACAGCAAAACCGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTTTGCCGCAGCACGTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCCAAACTGGCAGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTCATAACCTCCTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCATGACTGATCATTGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCAAACCTCTCTGTGCCTTTACAGAGTGCGCAAGCCCGGAATCGAACCGGG.\n"
     ]
    }
   ],
   "source": [
    "# PCR amplification and digest PCR and vector:\n",
    "pcr_amplication_list = batch_pcr(primer_df, template_sequence)\n",
    "pcr_digestion_list = batch_digestion_esp3i(pcr_amplication_list)\n",
    "vector_digestion = Esp3I.catalyze(vector_sequence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T00:38:05.576320Z",
     "start_time": "2023-11-01T00:38:05.548799100Z"
    }
   },
   "id": "6b6494baf6921038"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligating fragment #1\n",
      "ligating fragment #2\n",
      "ligating fragment #3\n",
      "ligating fragment #4\n",
      "ligating fragment #5\n",
      "ligating fragment #6\n",
      "ligating fragment #7\n",
      "ligating fragment #8\n",
      "ligating fragment #9\n",
      "ligating fragment #10\n",
      "ligating fragment #11\n",
      "ligating fragment #12\n",
      "ligating fragment #13\n",
      "ligating fragment #14\n",
      "ligating fragment #15\n",
      "ligating fragment #16\n",
      "ligating fragment #17\n",
      "ligating fragment #18\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the GGA final product (can also use the gga_ligation_3 function)\n",
    "final_product_4 = gga_ligation_4(vector_digestion, pcr_digestion_list)\n",
    "# Create a SeqRecord object with your sequence and an identifier\n",
    "record = SeqRecord(final_product_4, id='test', description='Golden Gate Assembly final product')\n",
    "\n",
    "# Write the SeqRecord to a FASTA file\n",
    "current_datetime = datetime.datetime.now()\n",
    "date_time_str = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "gga_product_path = desktop + '/' + gga_product_file + date_time_str + '.fa'\n",
    "SeqIO.write(record, gga_product_path, 'fasta')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T01:06:19.462805400Z",
     "start_time": "2023-11-01T01:06:19.364149800Z"
    }
   },
   "id": "fd76559c8b8b43a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "44501e929271087a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
