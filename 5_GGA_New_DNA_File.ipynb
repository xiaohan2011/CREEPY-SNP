{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T15:58:56.304544700Z",
     "start_time": "2023-10-31T15:58:56.291597400Z"
    }
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.Restriction import *\n",
    "import pandas as pd\n",
    "import os\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "outputs": [],
   "source": [
    "#Input filename\n",
    "template = \"pXW466.fa\"\n",
    "vector = \"pXW467.fa\"\n",
    "primer = 'primers.txt'\n",
    "primer2 = 'pXW470_creepy_primer_2023-10-30_18-21-24.txt'\n",
    "\n",
    "#Output filename (partial)\n",
    "gga_product_file = \"GGA_product_\" \n",
    "\n",
    "desktop = os.path.expanduser(\"~/Desktop\")\n",
    "template = desktop + \"/\" + template\n",
    "vector = desktop + \"/\" + vector\n",
    "primer_path = desktop + '/' + primer\n",
    "primer_path_2 = desktop + '/' + primer2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T15:58:56.603635800Z",
     "start_time": "2023-10-31T15:58:56.595626100Z"
    }
   },
   "id": "9e13b2d6f1345a98"
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [],
   "source": [
    "# Load the fasta sequence from the file\n",
    "def load_fasta_sequence(file_path):\n",
    "    with open(file_path, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            return record.seq.upper()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T15:58:56.980209Z",
     "start_time": "2023-10-31T15:58:56.962204500Z"
    }
   },
   "id": "81b75d6baf56b90a"
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [],
   "source": [
    "# Function to load primer pairs from a file\n",
    "def load_primer_pairs(file_path):\n",
    "    primer_pairs = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        for i in range(1, len(lines), 2):\n",
    "            forward_primer = lines[i].split('\\t')[1]\n",
    "            reverse_primer = lines[i + 1].split('\\t')[1]\n",
    "            primer_pairs.append((Seq(forward_primer.upper()), Seq(reverse_primer.upper())))\n",
    "    return pd.DataFrame(primer_pairs, columns=['Fwd', 'Rev'])        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T15:58:57.348201Z",
     "start_time": "2023-10-31T15:58:57.336197300Z"
    }
   },
   "id": "4cb1f02d08e73cb8"
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [],
   "source": [
    "# Load the data from the text file\n",
    "def load_primer_pairs_2(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "    \n",
    "    # Initialize lists to store the primer names and sequences\n",
    "    primer_names = []\n",
    "    primer_sequences = []\n",
    "    \n",
    "    # Flag to start recording primer data\n",
    "    record_primers = False\n",
    "    \n",
    "    # Iterate through the lines in the file\n",
    "    for line in lines:\n",
    "        # Check if the lowercase version of the line contains \"primer\" to start recording primer data\n",
    "        if \"primer\" in line.lower():\n",
    "            record_primers = True\n",
    "            continue\n",
    "        \n",
    "        # Stop recording when other information begins\n",
    "        if not line.strip():\n",
    "            record_primers = False\n",
    "        \n",
    "        # If we are recording primer data, split the line and extract the primer name and sequence\n",
    "        if record_primers:\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                primer_name = parts[0]\n",
    "                primer_sequence = Seq(parts[1].strip())\n",
    "                primer_names.append(primer_name)\n",
    "                primer_sequences.append(Seq(primer_sequence.upper()))\n",
    "    \n",
    "    # Create a Pandas DataFrame from the collected data\n",
    "    data = {'Primer': primer_names, 'Sequence': primer_sequences}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return  df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T15:58:57.695278Z",
     "start_time": "2023-10-31T15:58:57.684278500Z"
    }
   },
   "id": "95a2ad26652dd2eb"
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [],
   "source": [
    "# Function for PCR amplification with sticky ends\n",
    "def pcr_amplification_with_sticky_ends(template, forward_primer, reverse_primer):\n",
    "    # Define the sequences for sticky ends\n",
    "    fwd_anneal = forward_primer[-15:]\n",
    "    rev_anneal_rc = reverse_primer[-15:].reverse_complement()\n",
    "    \n",
    "    # Find the positions where the sticky ends anneal to the template\n",
    "    fwd_anneal_pos = template.find(fwd_anneal)\n",
    "    rev_anneal_pos = template.find(rev_anneal_rc)\n",
    "    \n",
    "    # Check if both sticky ends are present in the template\n",
    "    if fwd_anneal_pos != -1 and rev_anneal_pos != -1:\n",
    "        # Extract the template regions between the sticky ends\n",
    "        template_region = template[fwd_anneal_pos + len(fwd_anneal):rev_anneal_pos]\n",
    "        \n",
    "        # Amplify the template region with the primers\n",
    "        pcr_product = forward_primer + template_region + reverse_primer.reverse_complement()\n",
    "        print(f\"Amplified template with {str(forward_primer)} and {str(reverse_primer)}.\")\n",
    "        \n",
    "        return pcr_product\n",
    "\n",
    "    else:\n",
    "        # One or both sticky ends are not present in the template\n",
    "        print(f\"WARNING: primers {str(forward_primer)} and {str(reverse_primer)} do NOT amplify the template.\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T15:58:58.093642700Z",
     "start_time": "2023-10-31T15:58:58.071638900Z"
    }
   },
   "id": "b383516f4e62999f"
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [],
   "source": [
    "def batch_pcr(p_df, temp_seq):\n",
    "    pcr_prod_list = []\n",
    "    \n",
    "    for i in range(0, p_df.shape[0], 2):\n",
    "        try: product = pcr_amplification_with_sticky_ends(temp_seq, p_df['Sequence'][i], p_df['Sequence'][i+1])\n",
    "        except None: pass\n",
    "        pcr_prod_list.append(product)\n",
    "        \n",
    "    return pcr_prod_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T15:58:58.431720700Z",
     "start_time": "2023-10-31T15:58:58.417717900Z"
    }
   },
   "id": "69b19b8b98518626"
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [],
   "source": [
    "def batch_digestion_esp3i(pcr_list):\n",
    "    pcr_dig_list = []\n",
    "    for i in range(len(pcr_list)):\n",
    "        pcr_dig_list.append(Esp3I.catalyze(pcr_list[i]))\n",
    "    return pcr_dig_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T15:58:58.973363900Z",
     "start_time": "2023-10-31T15:58:58.961360300Z"
    }
   },
   "id": "2d15e4a10cea5f9"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "def gga_ligation(vect_dig, insert_list):\n",
    "    final_prod = vect_dig[0]\n",
    "    \n",
    "    if vect_dig[1][:4] == insert_list[0][1][:4]:\n",
    "        final_prod = final_prod + insert_list[0][1]\n",
    "        print(f'ligating fragment 1')\n",
    "\n",
    "    for i in range(len(insert_list)-1):\n",
    "        if insert_list[i][2][:4] == insert_list[i+1][1][:4]:\n",
    "            final_prod = final_prod + insert_list[i+1][1]\n",
    "            print(f'ligating fragment {i+2}')\n",
    "            \n",
    "    if insert_list[-1][2][:4] == vect_dig[2][:4]:\n",
    "        final_prod = final_prod + vect_dig[2]       \n",
    "        \n",
    "    return final_prod  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26173c0e1ac5f462"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "def gga_ligation_2(vect_dig, insert_list):\n",
    "    final_prod = vect_dig[0]\n",
    "    \n",
    "    sticky_end = {}\n",
    "    if vect_dig[1][:4] == insert_list[0][1][:4]:\n",
    "        final_prod = final_prod + insert_list[0][1]\n",
    "        print(f'ligating fragment 1')\n",
    "\n",
    "    for i in range(len(insert_list)-1):\n",
    "        if insert_list[i][2][:4] == insert_list[i+1][1][:4]:\n",
    "            final_prod = final_prod + insert_list[i+1][1]\n",
    "            print(f'ligating fragment {i+2}')\n",
    "            \n",
    "    if insert_list[-1][2][:4] == vect_dig[2][:4]:\n",
    "        final_prod = final_prod + vect_dig[2]       \n",
    "        \n",
    "        \n",
    "        \n",
    "    return final_prod   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f74a5d201d58d310"
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "outputs": [],
   "source": [
    "def make_sticky_ends_df(vect_frag, insert_list):\n",
    "    # Initialize lists to store the extracted sticky ends\n",
    "    sticky_ends1 = ['NA']\n",
    "    sticky_ends2 = [str(vect_frag[1][:4])]\n",
    "    \n",
    "    # Extract the first 4 bases from the last 2 Seq objects in each tuple\n",
    "    for tup in insert_list:\n",
    "        sticky_end1 = str(tup[1][:4])\n",
    "        sticky_end2 = str(tup[2][:4])\n",
    "        sticky_ends1.append(sticky_end1)\n",
    "        sticky_ends2.append(sticky_end2)\n",
    "    \n",
    "    sticky_ends1.append(str(vect_frag[2][:4]))\n",
    "    sticky_ends2.append('NA')\n",
    "    \n",
    "    # Create a Pandas DataFrame from the collected data\n",
    "    data = {'Sticky_End1': sticky_ends1, 'Sticky_End2': sticky_ends2}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T17:51:13.735089300Z",
     "start_time": "2023-10-31T17:51:13.719454200Z"
    }
   },
   "id": "1623570e5be1e109"
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [],
   "source": [
    "def gga_ligation_3(vect_dig, insert_list):\n",
    "    #Initialize final_prod to be the left part of the digested vector first:\n",
    "    final_prod = vect_dig[0]\n",
    "    \n",
    "    sticky_ends_df = make_sticky_ends_df(vect_dig, insert_list)\n",
    "    \n",
    "    # Check if adjacent sticky ends are compatible:\n",
    "    for i in range(sticky_ends_df.shape[0]-1):\n",
    "        if sticky_ends_df['Sticky_End2'][i] != sticky_ends_df['Sticky_End1'][i+1]:\n",
    "            print(f'Sticky end #{i+1} is not compatible')\n",
    "            break\n",
    "    \n",
    "    # Check if all sticky ends are unique and none are not ligating with reverse complements:\n",
    "    sticky_ends_df['Sticky_End1_RevComp'] = sticky_ends_df['Sticky_End1'].apply(lambda x: str(Seq(x).reverse_complement()))\n",
    "    are_all_unique = pd.concat([sticky_ends_df['Sticky_End1'][1:], sticky_ends_df['Sticky_End1_RevComp'][1:]]).is_unique\n",
    "    if not are_all_unique:\n",
    "        print('WARNING: some sticky ends are not unique')\n",
    "        pass\n",
    "   \n",
    "    for i in range(len(insert_list)):\n",
    "        final_prod = final_prod + insert_list[i][1]\n",
    "        print(f'ligating fragment {i+1}')\n",
    "    \n",
    "    final_prod = final_prod + vect_dig[2]       \n",
    "               \n",
    "    return final_prod   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:25:50.720938300Z",
     "start_time": "2023-10-31T18:25:50.705291800Z"
    }
   },
   "id": "9b043c1e7488dbdb"
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "outputs": [],
   "source": [
    "# Load plasmid sequences and  primer pairs:\n",
    "template_sequence = load_fasta_sequence(template)\n",
    "vector_sequence = load_fasta_sequence(vector)\n",
    "primer_df = load_primer_pairs_2(primer_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:27:18.967150Z",
     "start_time": "2023-10-31T18:27:18.935884800Z"
    }
   },
   "id": "f7260c6f4cf792db"
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amplified template with ACGTCTCCGACTTTAGAAAGTGAGTCATTTTGGGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCCCACAGCATGGTTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGTGGCCAAGCAGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCATGCTCAGCCTTTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGCATCTGCGCAGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTCTATCAGAATATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCTAGATAACTCTAGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCCCTAGAGGCTTCATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCTAGGGCTTCTCGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTAGTAATTTTTCTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCACTAGCCATAATGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTTTTACTACCGGTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCAAAAATTCATTTGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCGTTAGTGGTGGCTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCTAACAGCCACAGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCAGAAGGAAGCCATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCTTCTAGAAAGGCGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTTCCTCTGTGTATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGGAAAGAGGAAGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCGCAGCCATGTCTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCCTGCACATTTTCTGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCCAGTTGCAGGTTGCATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCACTGATCTGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCCTTCCCCTTCCGTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGAAGAAGGGGCCGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTCTCTGAGGCATGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGAGAATTTCTCTAGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCGCTCTCCTCTGCTTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCGAGCACGCGTGGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCGTCAAAGGGATTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCTGACAGCAAAACCGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTTTGCCGCAGCACGTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCCAAACTGGCAGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCTCATAACCTCCTGCGCAAGCCCGGAATCGAACCGGG.\n",
      "Amplified template with ACGTCTCCATGACTGATCATTGTTTTAGAGCTAGAAATAGCAAGTTA and ACGTCTCCAAACCTCTCTGTGCCTTTACAGAGTGCGCAAGCCCGGAATCGAACCGGG.\n"
     ]
    }
   ],
   "source": [
    "# PCR amplification and digest PCR and vector:\n",
    "pcr_amplication_list = batch_pcr(primer_df, template_sequence)\n",
    "pcr_digestion_list = batch_digestion_esp3i(pcr_amplication_list)\n",
    "vector_digestion = Esp3I.catalyze(vector_sequence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:27:19.845790300Z",
     "start_time": "2023-10-31T18:27:19.820143Z"
    }
   },
   "id": "6b6494baf6921038"
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligating fragment 1\n",
      "ligating fragment 2\n",
      "ligating fragment 3\n",
      "ligating fragment 4\n",
      "ligating fragment 5\n",
      "ligating fragment 6\n",
      "ligating fragment 7\n",
      "ligating fragment 8\n",
      "ligating fragment 9\n",
      "ligating fragment 10\n",
      "ligating fragment 11\n",
      "ligating fragment 12\n",
      "ligating fragment 13\n",
      "ligating fragment 14\n",
      "ligating fragment 15\n",
      "ligating fragment 16\n",
      "ligating fragment 17\n",
      "ligating fragment 18\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_product = gga_ligation_3(vector_digestion, pcr_digestion_list)\n",
    "# Create a SeqRecord object with your sequence and an identifier\n",
    "record = SeqRecord(final_product, id='test', description='Golden Gate Assembly final product')\n",
    "\n",
    "# Write the SeqRecord to a FASTA file\n",
    "current_datetime = datetime.datetime.now()\n",
    "date_time_str = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "gga_product_path = desktop + '/' + gga_product_file + date_time_str + '.fa'\n",
    "SeqIO.write(record, gga_product_path, 'fasta')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:27:20.981807900Z",
     "start_time": "2023-10-31T18:27:20.950542300Z"
    }
   },
   "id": "be8d296d1aec953a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "684c74ce2329081e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
